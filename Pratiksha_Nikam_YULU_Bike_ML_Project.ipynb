{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "7wuGOrhz0itI",
        "578E2V7j08f6",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "TfvqoZmBfxKf",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "7AN1z2sKpx6M",
        "Z-hykwinpx6N",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NikamPratiksha0506/Yulu-Bike-Sharing-Demand-Prediction/blob/main/Pratiksha_Nikam_YULU_Bike_ML_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -  Yulu Bike Sharing Demand Prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - EDA/Regression/Classification/Unsupervised\n",
        "##### **Contribution**    - Individual/Team\n",
        "##### **Team Member 1 -**\n",
        "##### **Team Member 2 -**\n",
        "##### **Team Member 3 -**\n",
        "##### **Team Member 4 -**"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**   \n",
        "Bike demand prediction is a crucial challenge for bike rental companies, as accurately forecasting demand helps optimize inventory management and pricing strategies. In this project, I aimed to develop a supervised regression machine learning model to predict bike demand for a given time period.\n",
        "\n",
        "The original dataset, sourced from a bike-sharing company, contained information on the number of bikes rented, time and date details, weather conditions, and seasonality factors. Additionally, it included information on special conditions like holidays and whether it was a working or non-working day.\n",
        "\n",
        "After performing data preprocessing and cleaning, I split the dataset into training and test sets. I then trained multiple machine learning models using the training data and experimented with various model architectures and hyperparameter settings. After evaluation, I selected the best-performing model based on its test data results.\n",
        "\n",
        "To measure the model's performance, I used multiple evaluation metrics, including:\n",
        "\n",
        "Mean Absolute Error (MAE)\n",
        "\n",
        "Root Mean Squared Error (RMSE)\n",
        "\n",
        "R-squared (R²) Score\n",
        "\n",
        "The final model achieved an R² score of 0.88 and a mean absolute error of 2.58, indicating high prediction accuracy.\n",
        "\n",
        "Additionally, I conducted ablation studies to understand the impact of individual features on the model’s performance. I found that temperature, weather conditions, and seasonality features had the most significant effect on bike demand."
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the summary here within 500-600 words."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the evolving landscape of urban mobility, companies like Yulu Bike are at the forefront of providing efficient and eco-friendly transportation solutions. Accurate prediction of bike-sharing demand is crucial for optimizing fleet management, enhancing customer satisfaction, and maximizing operational efficiency. By analyzing data related to bike-sharing demand, Yulu Bike aims to gain a deeper understanding of the factors influencing bike rentals. The dataset includes a range of variables such as weather conditions, time of day, and special events, which impact bike usage patterns.\n",
        "\n",
        "Leveraging this data, Yulu Bike can:\n",
        "\n",
        "1. Optimize Fleet Management:                 \n",
        "Predicting demand based on factors like temperature, humidity, and time of day allows Yulu Bike to deploy bikes more strategically, ensuring availability during peak times and reducing idle resources.\n",
        "\n",
        "2. Enhance Customer Experience:                     \n",
        "By understanding how external factors such as weather and holidays affect demand, Yulu Bike can better align their service offerings with customer needs, improving overall user satisfaction.\n",
        "\n",
        "3. Improve Operational Efficiency:                \n",
        "Accurate demand forecasts help in planning maintenance schedules and managing bike distribution across different areas, leading to more efficient operations.\n",
        "\n",
        "4. Adapt to Environmental Factors:              \n",
        "Insights into how weather conditions and seasonal variations impact bike usage enable Yulu Bike to adjust their strategies in real-time, ensuring optimal service delivery throughout the year."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "\n",
        "import numpy as np  # Import NumPy for numerical operations\n",
        "import pandas as pd  # Import Pandas for data manipulation and analysis\n",
        "import datetime as dt  # Import datetime for working with dates and times\n",
        "\n",
        "import matplotlib.pyplot as plt  # Import Matplotlib for data visualization\n",
        "import seaborn as sns  # Import Seaborn for enhanced data visualization\n",
        "from scipy import stats  # Import SciPy for statistical functions\n",
        "from sklearn.preprocessing import LabelEncoder  # Import LabelEncoder for converting categorical labels to numbers\n",
        "from sklearn.preprocessing import StandardScaler  # Import StandardScaler for feature scaling\n",
        "\n",
        "# Importing Pandas again (unnecessary, already imported above)\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split  # Import train_test_split for splitting data into training and test sets\n",
        "\n",
        "from sklearn.linear_model import LinearRegression  # Import LinearRegression for building linear regression models\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score  # Import metrics for evaluating model performance\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV  # Import GridSearchCV for hyperparameter tuning with grid search\n",
        "from sklearn.ensemble import RandomForestRegressor  # Import RandomForestRegressor for building random forest regression models\n",
        "from sklearn.model_selection import cross_val_score  # Import cross_val_score for cross-validation scoring\n",
        "\n",
        "# Importing LinearRegression again (unnecessary, already imported above)\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import GridSearchCV  # Import GridSearchCV again (unnecessary, already imported above)\n",
        "from sklearn.preprocessing import StandardScaler  # Import StandardScaler again (unnecessary, already imported above)\n",
        "from sklearn.pipeline import Pipeline  # Import Pipeline for creating a machine learning pipeline\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor  # Import RandomForestRegressor again (unnecessary, already imported above)\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV  # Import RandomizedSearchCV for hyperparameter tuning with randomized search\n",
        "from sklearn.ensemble import RandomForestRegressor  # Import RandomForestRegressor again (unnecessary, already imported above)\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score  # Import metrics again (unnecessary, already imported above)\n",
        "\n",
        "import numpy as np  # Import NumPy again (unnecessary, already imported above)\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV  # Importing modules for data splitting and random search for hyperparameter tuning\n",
        "from sklearn.ensemble import GradientBoostingRegressor  # Import GradientBoostingRegressor for building gradient boosting regression models\n",
        "from sklearn.tree import DecisionTreeRegressor  # Import DecisionTreeRegressor for building decision tree regression models\n",
        "\n",
        "# Importing warnings library. The warnings module handles warnings in Python.\n",
        "import warnings  # Import warnings to manage warning messages\n",
        "warnings.filterwarnings('ignore')  # Ignore warning messages during execution\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "IFZ1rxrMZRFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "bike_df = pd.read_csv('/content/drive/MyDrive/ML-Projects/SeoulBikeData.csv', encoding=\"latin-1\")"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "bike_df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#viewing the last 5 data of the datase\n",
        "bike_df.tail()"
      ],
      "metadata": {
        "id": "PbejSTw6a9Dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "rows_columns = bike_df.shape\n",
        "print(f'this dataset has {rows_columns[0]} rows and it has {rows_columns[1]} columns' )"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "bike_df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "print(f'The No.Of Duplicate Value in Bike Rental Dataset is {bike_df.duplicated().sum()}')"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "bike_df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(7, 5))\n",
        "sns.heatmap(bike_df.isnull(), cmap=\"viridis\", cbar=False)\n",
        "plt.title(\"Missing Values Heatmap\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Overview of the Dataset:              \n",
        "The dataset consists of 8760 rows and 14 columns.\n",
        "It provides data on bike rentals with information such as weather conditions, date, time, and operational status.\n",
        "There are no missing or duplicate values.\n",
        "2. Data Types and Column Categorization:              \n",
        "a. Date/Time:\n",
        "Date: Currently stored as an object (string) – 365 unique values. This needs to be converted into datetime format for accurate time-based analysis.\n",
        "Hour: Integer – 24 unique values.\n",
        "b. Numerical Columns (Continuous):\n",
        "Rented Bike Count: Integer – 2166 unique values.\n",
        "Temperature (°C): Float – 546 unique values.\n",
        "Humidity (%): Integer – 90 unique values.\n",
        "Wind Speed (m/s): Float – 65 unique values.\n",
        "Visibility (10m): Integer – 1789 unique values.\n",
        "Dew Point Temperature (°C): Float – 556 unique values.\n",
        "Solar Radiation (MJ/m²): Float – 345 unique values.\n",
        "Rainfall (mm): Float – 61 unique values.\n",
        "Snowfall (cm): Float – 51 unique values.\n",
        "c. Categorical Columns:\n",
        "Seasons: Object (string) – 4 unique values (Winter, Spring, Summer, Fall).\n",
        "Holiday: Object (string) – 2 unique values (Yes, No).\n",
        "Functioning Day: Object (string) – 2 unique values (Yes, No).\n",
        "3. Additional Insights:                    \n",
        "The Date column needs to be converted from string to datetime format for better time-series analysis.\n",
        "The dataset is clean and ready for analysis, making it suitable for time-series forecasting, weather-based analysis, or predictive modeling of bike rentals based on external factors like weather and holidays."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "\n",
        "\n",
        "print(f'Features: {bike_df.columns.tolist()}')"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "bike_df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Features description\n",
        "\n",
        "Breakdown of Our Features:\n",
        "\n",
        "Date : The date of the day, during 365 days from 01/12/2017 to 30/11/2018, formating in DD/MM/YYYY, type : str, we need to convert into datetime format.\n",
        "\n",
        "Rented Bike Count : Number of rented bikes per hour which our dependent variable and we need to predict that, type : int\n",
        "\n",
        "Hour: The hour of the day, starting from 0-23 it's in a digital time format, type : int, we need to convert it into category data type.\n",
        "\n",
        "Temperature(°C): Temperature in Celsius, type : Float\n",
        "\n",
        "Humidity(%): Humidity in the air in %, type : int\n",
        "\n",
        "Wind speed (m/s) : Speed of the wind in m/s, type : Float\n",
        "\n",
        "Visibility (10m): Visibility in m, type : int\n",
        "\n",
        "Dew point temperature(°C): Temperature at the beggining of the day, type : Float\n",
        "\n",
        "Solar Radiation (MJ/m2): Sun contribution, type : Float\n",
        "\n",
        "Rainfall(mm): Amount of raining in mm, type : Float\n",
        "\n",
        "Snowfall (cm): Amount of snowing in cm, type : Float\n",
        "\n",
        "Seasons: Season of the year, type : str, there are only 4 season's in data .\n",
        "\n",
        "Holiday: If the day is holiday period or not, type: str\n",
        "\n",
        "Functioning Day: If the day is a Functioning Day or not, type : str"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for i in bike_df.columns.tolist():\n",
        "   print(f'The No. of Unique Value in {i} is : {bike_df[i].nunique()}')"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "\n",
        "bike_df = bike_df.rename(columns = {'Rented Bike Count':'Rented_Bike_Count',\n",
        "                                'Temperature(°C)':'Temperature',\n",
        "                                'Humidity(%)':'Humidity',\n",
        "                                'Wind speed (m/s)':'Wind_speed',\n",
        "                                'Visibility (10m)':'Visibility',\n",
        "                                'Dew point temperature(°C)':'Dew_point_temperature',\n",
        "                                'Solar Radiation (MJ/m2)':'Solar_Radiation',\n",
        "                                'Rainfall(mm)':'Rainfall',\n",
        "                                'Snowfall (cm)':'Snowfall',\n",
        "                                'Functioning Day':'Functioning_Day'})"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bike_df.head()"
      ],
      "metadata": {
        "id": "urY93wFghrq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bike_df['Date'] = bike_df['Date'].str.replace('-','/')\n",
        "bike_df['Date'] = pd.to_datetime(bike_df['Date'], format='%d/%m/%Y')"
      ],
      "metadata": {
        "id": "dIFO08nYh41O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, split date into separate year, month, and day columns\n",
        "\n",
        "bike_df['year'] = bike_df['Date'].dt.year\n",
        "bike_df['month'] = bike_df['Date'].dt.month_name()\n",
        "bike_df['day'] = bike_df['Date'].dt.day_name()"
      ],
      "metadata": {
        "id": "t08MjKszid9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vdxjNT7-iebV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a new column of \"weekdays_weekend\"\n",
        "\n",
        "bike_df['weekday_or_weekend'] = bike_df['day'].apply(lambda x : 'Weekend' if x == 'Saturday' or x =='Sunday' else 'Weekday')"
      ],
      "metadata": {
        "id": "jvzbHXH_izWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bike_df.head()"
      ],
      "metadata": {
        "id": "5RjR5UWajGLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Renaming Columns:\n",
        "\n",
        "Standardized column names by replacing spaces with underscores and simplifying names (e.g., 'Rented Bike Count' became 'Rented_Bike_Count', 'Temperature(°C)' became 'Temperature', etc.).\n",
        "\n",
        "2. Date Formatting:\n",
        "\n",
        "Replaced the hyphen '-' with a slash '/' in the 'Date' column to standardize the date format.\n",
        "Converted the 'Date' column into a datetime format using the format '%d/%m/%Y'.\n",
        "\n",
        "3. Date Splitting:\n",
        "\n",
        "Created new columns for 'year', 'month', and 'day' from the 'Date' column for easier time-based analysis.\n",
        "\n",
        "4. Weekday vs. Weekend:\n",
        "\n",
        "Created a new column 'weekday_or_weekend' that categorizes each entry as either 'Weekend' (Saturday or Sunday) or 'Weekday' based on the day of the week.\n",
        "\n",
        "Insights so far:\n",
        "\n",
        "Data Consistency:\n",
        "\n",
        "After standardizing and cleaning the dataset, the date column is now properly formatted, which helps in performing time-based aggregations or analysis.\n",
        "\n",
        "Feature Enrichment:\n",
        "\n",
        "The new 'weekday_or_weekend' column allows for quick comparison of bike rentals between weekdays and weekends.\n",
        "The split of 'Date' into 'year', 'month', and 'day' opens opportunities to explore seasonal trends, daily variations, or yearly growth in bike rentals.\n",
        "With these manipulations, you can now explore various insights, such as:\n",
        "\n",
        "Trends in bike rentals over months or seasons.\n",
        "Impact of weekends on bike rentals.\n",
        "Correlation between weather conditions (e.g., temperature, snowfall, rainfall) and bike rentals.\n",
        "\n"
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "\n",
        "# Plotting a histogram for analyzing the distribution of temperature values\n",
        "\n",
        "# Set the figure size for the plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot a histogram of the 'Temperature' column with a kernel density estimate (KDE)\n",
        "sns.histplot(bike_df['Temperature'], kde=True, bins=10, color='skyblue', edgecolor='Black')\n",
        "\n",
        "# Set the title of the plot\n",
        "plt.title('Temperature Distribution')\n",
        "\n",
        "# Label the x-axis\n",
        "plt.xlabel('Temperature (°C)')\n",
        "\n",
        "# Label the y-axis\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose a histogram with a KDE curve because it is one of the best tools for conducting univariate analysis (analyzing a single variable) when the goal is to understand the distribution of continuous numerical data, like temperature.\n",
        "\n",
        "Reasons for choosing this chart:\n",
        "Visualizing Frequency Distribution:\n",
        "\n",
        "The histogram clearly shows how frequently different temperature values occur, which helps identify common temperature ranges and the overall shape of the distribution.\n",
        "Distribution Shape and Skewness:\n",
        "\n",
        "A histogram reveals the shape of the distribution, whether it is normal, skewed, or has multiple peaks. In this case, it helps to see the slightly negatively skewed nature of the temperature data.\n",
        "The KDE curve smoothens out the data to give a better understanding of the underlying density of the data points, complementing the histogram.\n",
        "Outliers and Spread:\n",
        "\n",
        "The histogram, combined with the KDE curve, allows for quick identification of outliers (if any) and provides insights into the spread of the temperature data, such as the range and where most data points are concentrated.\n",
        "Summary of Central Tendency:\n",
        "\n",
        "It also helps to identify the central tendency of the data (e.g., where most of the temperature values fall). In this chart, we see that most temperatures lie between 10-20°C, which is crucial for summarizing the typical behavior of temperature in the dataset.\n",
        "Frequency and Distribution in One View:\n",
        "\n",
        "This chart efficiently combines the frequency of temperature values (from the histogram) and a smooth estimation of the probability distribution (from the KDE), giving a more comprehensive view of the data in a single chart."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the chart, several key insights about the **Temperature** data can be gathered:\n",
        "\n",
        "### 1. **Temperature Distribution**:\n",
        "   - The data shows a **roughly normal distribution**, with most temperature values concentrated between **0°C and 25°C**.\n",
        "   - The distribution is slightly **negatively skewed**, meaning colder temperatures (below the mean) occur slightly more frequently than very warm temperatures.\n",
        "\n",
        "### 2. **Most Frequent Temperature Range**:\n",
        "   - The **peak of the distribution** occurs around **10°C to 20°C**, indicating this is the most common temperature range in the dataset. This could imply that the majority of days or hours in the dataset experience moderate temperatures.\n",
        "\n",
        "### 3. **Extremes Are Less Common**:\n",
        "   - **Extreme temperatures**, both **very cold** (below -10°C) and **very hot** (above 30°C), are relatively rare in the dataset, as seen from the lower bars in these regions.\n",
        "   - This suggests that the dataset primarily contains mild to moderate temperature values, with fewer extreme weather conditions.\n",
        "\n",
        "### 4. **Spread of Temperature**:\n",
        "   - The temperature values cover a wide range, from **around -15°C to 35°C**, showing that the data includes both cold and hot periods.\n",
        "   - However, the majority of the data is concentrated between **0°C and 25°C**, with temperatures below 0°C and above 25°C occurring less frequently.\n",
        "\n",
        "### 5. **Outliers**:\n",
        "   - There are no extreme outliers visible in the histogram, suggesting that the temperature values are relatively consistent, without major deviations from the normal range.\n",
        "\n",
        "### 6. **Skewness Insight**:\n",
        "   - The **slight left skew** (negative skewness) indicates that colder temperatures are slightly more frequent than very high temperatures. This can be important depending on the context, such as in seasonal or location-based temperature analysis.\n",
        "\n"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Positive Business Impact Insights:**\n",
        "\n",
        "The insights gained from the temperature distribution can be leveraged to create positive business outcomes, particularly for businesses where **temperature plays a role in customer behavior**, product demand, or service delivery. Here’s how:\n",
        "\n",
        "1. **Optimal Temperature for Business Operations**:\n",
        "   - The most common temperature range, between **10°C and 20°C**, is moderate and generally comfortable for outdoor activities. If the business involves outdoor services (e.g., bike rentals, outdoor events, tourism), knowing that this range is frequent allows the business to **plan promotions** and **optimize staffing levels** for these temperature conditions.\n",
        "\n",
        "2. **Seasonal Demand Forecasting**:\n",
        "   - If the data represents a specific season or location, knowing that extreme temperatures (below -10°C or above 30°C) are rare means that the business can focus more on planning for mild to warm weather. For example:\n",
        "     - **Bike rental services** may see higher demand in **moderate temperatures** (10°C to 20°C) and can increase inventory or staffing accordingly.\n",
        "     - **Retail businesses** can **stock temperature-sensitive products** (like seasonal clothing) in line with the common temperature ranges, optimizing inventory and sales.\n",
        "\n",
        "3. **Energy Management**:\n",
        "   - Businesses involved in **energy services**, such as heating or cooling, can anticipate that energy demand will likely peak when temperatures move towards the extremes (cold or hot). However, since extreme temperatures are rare, businesses can focus on efficiency measures during **moderate temperature periods** to reduce operational costs.\n",
        "\n",
        "4. **Customer Comfort and Experience**:\n",
        "   - Businesses that provide **customer experiences (e.g., restaurants with outdoor seating, theme parks)** can optimize operations during the most common temperature ranges, ensuring that they provide the best services during periods of moderate temperatures when customers are more likely to engage in outdoor activities.\n",
        "\n",
        "### **Negative Growth Insights and Justifications:**\n",
        "\n",
        "1. **Limited Business During Extreme Conditions**:\n",
        "   - The histogram shows that temperatures below **-10°C and above 30°C** are infrequent. For businesses that heavily rely on **extreme weather conditions** (such as ski resorts or cold-weather clothing), this distribution may indicate **limited opportunities** to capitalize on extreme cold weather.\n",
        "     - **Negative Impact**: If a business model is built around extreme conditions, this can lead to **lower revenue growth** or **idle periods** when extreme weather is less frequent.\n",
        "\n",
        "2. **Over-reliance on Rare Events**:\n",
        "   - If a business mistakenly expects extreme temperatures to occur more frequently, it may **over-invest** in resources or products designed for these rare conditions (e.g., excessive winter gear or cooling systems for high temperatures). This can lead to **excess inventory** or **unused resources**, resulting in **financial losses**.\n",
        "     - **Negative Impact**: Poor inventory management based on incorrect assumptions about temperature distribution can lead to **inefficiencies**, waste, or **reduced profitability**.\n",
        "\n",
        "3. **Not Preparing for Extreme Events**:\n",
        "   - Although extreme temperatures are rare, businesses that **fail to prepare for occasional extreme events** (such as sudden heat waves or cold snaps) could experience **operational challenges**. For instance:\n",
        "     - **Negative Impact**: A lack of contingency plans for extreme cold or heat (e.g., insufficient heating/cooling systems) can negatively impact customer satisfaction and lead to **business disruption** during these rare events.\n",
        "\n"
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "\n",
        "# Visualizing the distribution of Humidity in the dataset\n",
        "\n",
        "# Set the figure size for the plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot a histogram of the 'Humidity' column with a kernel density estimate (KDE)\n",
        "\n",
        "sns.histplot(x=bike_df['Humidity'], kde=True, bins=20, color='skyblue')\n",
        "\n",
        "# Set the title of the plot\n",
        "plt.title('Distribution Of Humidity')\n",
        "\n",
        "# Label the x-axis\n",
        "plt.xlabel('Humidity')\n",
        "\n",
        "# Label the y-axis\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "\n",
        "# Sum Of Rented Bikes According To Month\n",
        "\n",
        "# Set the color palette for the plot to 'viridis'\n",
        "sns.set_palette('viridis')\n",
        "\n",
        "# Create a figure and axis with specified size for the plot\n",
        "fig, ax = plt.subplots(figsize=(6, 5))\n",
        "\n",
        "# Create a line plot to visualize the total number of rented bikes per month\n",
        "sns.lineplot(data=bike_df, x='month', y='Rented_Bike_Count', color='blue', marker='o')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "\n",
        "# Rented bike count by weekdays or weekends\n",
        "\n",
        "# Create a figure and axis with specified size for the plot\n",
        "fig, ax = plt.subplots(figsize=(3, 4))\n",
        "\n",
        "# Create a bar plot to visualize the count of rented bikes based on whether the day is a weekday or weekend\n",
        "sns.barplot(x=bike_df['weekday_or_weekend'], y=bike_df['Rented_Bike_Count'])\n",
        "\n",
        "# Set the title of the plot to indicate what the data represents\n",
        "plt.title('Rented Bike Count By Weekday or Weekend')\n",
        "\n",
        "# Label the x-axis\n",
        "plt.xlabel('Weekday Or Weekend')\n",
        "\n",
        "# Label the y-axis\n",
        "plt.ylabel('Rented Bike Count')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the figure size for better visibility\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Create a line plot with markers for each hour\n",
        "sns.lineplot(x='Hour', y='Rented_Bike_Count', data=bike_df, marker='o', color='blue')\n",
        "\n",
        "# Customize the title and labels\n",
        "plt.title('Rented Bike Count by Hour', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Hour of the Day', fontsize=12)\n",
        "plt.ylabel('Rented Bike Count', fontsize=12)\n",
        "\n",
        "# Add grid for better readability\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "# Chart - 6 visualization code\n",
        "\n",
        "# Create the bar plot\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.barplot(x='Holiday', y='Rented_Bike_Count', data=bike_df, palette='Set1', alpha=0.6)\n",
        "\n",
        "# Set the title and labels\n",
        "plt.title('Rented Bike Count on Holidays vs Non-Holidays', fontsize=16)\n",
        "plt.xlabel('Holiday', fontsize=12)\n",
        "plt.ylabel('Rented Bike Count', fontsize=12)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "\n",
        "# Set the figure size for the plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Create a bar plot to visualize the relationship between seasons and the count of rented bikes\n",
        "\n",
        "sns.barplot(x=bike_df['Seasons'], y=bike_df['Rented_Bike_Count'], palette='Set1')\n",
        "\n",
        "# Set the title of the plot to indicate what it represents\n",
        "plt.title('Rented Bike Count By Season')\n",
        "\n",
        "# Label the x-axis to indicate what the data represents\n",
        "plt.xlabel('Seasons')\n",
        "\n",
        "# Label the y-axis to indicate what the data represents\n",
        "plt.ylabel('Rented Bike Count')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "# Create a horizontal bar plot for weekly data\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=bike_df, x='Rented_Bike_Count', y='day', estimator=sum, palette='viridis')\n",
        "\n",
        "# Set title and labels\n",
        "plt.title('Total Rented Bike Count By Day', fontsize=16)\n",
        "plt.xlabel('Total Rented Bike Count', fontsize=12)\n",
        "plt.ylabel('Day', fontsize=12)\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "# Create the scatter plot with a trend line\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.regplot(data=bike_df, x='Humidity', y='Rented_Bike_Count',\n",
        "            marker='o', scatter_kws={'color': 'blue'}, line_kws={'color': 'red'})\n",
        "\n",
        "# Set title and labels\n",
        "plt.title('Rented Bike Count vs. Humidity', fontsize=16)\n",
        "plt.xlabel('Humidity (%)', fontsize=12)\n",
        "plt.ylabel('Rented Bike Count', fontsize=12)\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "# Create the scatter plot with a trend line for Visibility vs. Rented Bike Count\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.regplot(data=bike_df, x='Visibility', y='Rented_Bike_Count',\n",
        "            marker='o', scatter_kws={'color': 'blue'}, line_kws={'color': 'red'})\n",
        "\n",
        "# Set title and labels\n",
        "plt.title('Rented Bike Count vs. Visibility', fontsize=16)\n",
        "plt.xlabel('Visibility (10m)', fontsize=12)\n",
        "plt.ylabel('Rented Bike Count', fontsize=12)\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "# Create a figure and axis with a specified size for the plot\n",
        "fig = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "# Create a point plot to visualize the relationship between the hour of the day and the count of rented bikes\n",
        "sns.pointplot(data=bike_df, x='Hour', y='Rented_Bike_Count', hue='Seasons', palette='Set1')\n",
        "\n",
        "# Set the title of the plot to indicate what it represents\n",
        "ax.set(title='Count of Rented Bikes According to Seasons')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "# Drop non-numeric columns for correlation analysis\n",
        "numeric_df = bike_df.select_dtypes(include=['float64', 'int64'])\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = numeric_df.corr()\n",
        "\n",
        "# Set the size of the plot\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Create the heatmap\n",
        "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', square=True, cbar_kws={\"shrink\": .8})\n",
        "\n",
        "# Set the title\n",
        "plt.title('Correlation Matrix of Bike Rental Data', fontsize=16)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Test for Difference in Bike Rentals on Holidays vs. Non-Holidays**"
      ],
      "metadata": {
        "id": "j33b_1Sh4o6f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Hypotheses:\n",
        "- **Null Hypothesis (H₀):** The mean bike rental count on holidays is equal to the mean bike rental count on non-holidays.\n",
        "- **Alternative Hypothesis (H₁):** The mean bike rental count on holidays is different from the mean bike rental count on non-holidays."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "# Splitting the data into holidays and non-holidays\n",
        "holiday_data = bike_df[bike_df['Holiday'] == 'Holiday']['Rented_Bike_Count']\n",
        "non_holiday_data = bike_df[bike_df['Holiday'] == 'No Holiday']['Rented_Bike_Count']\n",
        "\n",
        "# Conducting the t-test\n",
        "t_stat, p_value = stats.ttest_ind(holiday_data, non_holiday_data, equal_var=False)\n",
        "\n",
        "print(f\"T-statistic: {t_stat}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# If p-value < 0.05, we reject the null hypothesis.\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject the null hypothesis: There is a significant difference in bike rentals on holidays vs. non-holidays.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No significant difference in bike rentals on holidays vs. non-holidays.\")\n"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Independent t-test** (specifically Welch's t-test since)."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The t-test is used to compare the means of two independent groups (in this case, holidays vs. non-holidays). Since we are comparing the average bike rentals between two distinct categories (Holiday and No Holiday), and the data is continuous (bike rental count), the independent t-test is appropriate. We also assume unequal variances, hence we used Welch's t-test."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test for Difference in Bike Rentals Across Seasons"
      ],
      "metadata": {
        "id": "dwpDWR4N7YC0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H₀): The mean bike rental count is the same across all seasons.\n",
        "Alternative Hypothesis (H₁): The mean bike rental count is different across seasons."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Perform Statistical Test to obtain P-Value\n",
        "# Grouping the data by seasons\n",
        "winter_data = bike_df[bike_df['Seasons'] == 'Winter']['Rented_Bike_Count']\n",
        "spring_data = bike_df[bike_df['Seasons'] == 'Spring']['Rented_Bike_Count']\n",
        "summer_data = bike_df[bike_df['Seasons'] == 'Summer']['Rented_Bike_Count']\n",
        "autumn_data = bike_df[bike_df['Seasons'] == 'Autumn']['Rented_Bike_Count']\n",
        "\n",
        "# Conducting the one-way ANOVA test\n",
        "f_stat, p_value = stats.f_oneway(winter_data, spring_data, summer_data, autumn_data)\n",
        "\n",
        "print(f\"F-statistic: {f_stat}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# If p-value < 0.05, we reject the null hypothesis.\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject the null hypothesis: There is a significant difference in bike rentals across seasons.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No significant difference in bike rentals across seasons.\")\n"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One-way ANOVA."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One-way ANOVA is used when comparing the means of more than two independent groups (in this case, four seasons: Winter, Spring, Summer, and Autumn). Since the data is continuous and we are testing whether the average bike rentals differ across the seasons, ANOVA is appropriate. It tests for significant differences between group means."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "c3KcvkEo7TD3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test for the Impact of Temperature on Bike Rentals"
      ],
      "metadata": {
        "id": "oYM-O6YC9c53"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H₀): There is no correlation between temperature and bike rentals.\n",
        "Alternative Hypothesis (H₁): There is a significant correlation between temperature and bike rentals.\n",
        "Test to Use:\n",
        "Pearson correlation (if data is normally distributed), or Spearman's rank correlation (if not)."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Pearson correlation test\n",
        "corr, p_value = stats.pearsonr(bike_df['Temperature'], bike_df['Rented_Bike_Count'])\n",
        "\n",
        "print(f\"Correlation coefficient: {corr}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# If p-value < 0.05, we reject the null hypothesis.\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject the null hypothesis: There is a significant correlation between temperature and bike rentals.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No significant correlation between temperature and bike rentals.\")\n"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pearson correlation test."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pearson correlation is used to measure the strength and direction of the linear relationship between two continuous variables (in this case, temperature and bike rentals). We chose this test because we want to assess whether there is a significant correlation between these two variables and how strong that relationship is, assuming the data is normally distributed."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "bike_df.isnull().sum()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "\n",
        "# Select numerical columns\n",
        "numerical_columns = ['Rented_Bike_Count', 'Temperature', 'Humidity', 'Wind_speed', 'Visibility', 'Dew_point_temperature']\n",
        "\n",
        "for i, column in enumerate(numerical_columns, 1):\n",
        "    plt.subplot(2, 3, i)\n",
        "    sns.boxplot(y=bike_df[column])\n",
        "    plt.title(f'Box Plot of {column}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treating The Outlier"
      ],
      "metadata": {
        "id": "uMauc735hwDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to remove outliers using IQR\n",
        "def remove_outliers_iqr(df, column):\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    # Filter out the outliers\n",
        "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
        "\n",
        "# List of numerical columns to treat\n",
        "numerical_columns = ['Rented_Bike_Count', 'Temperature', 'Humidity', 'Wind_speed', 'Visibility', 'Dew_point_temperature']\n",
        "\n",
        "# Apply the IQR method to treat outliers\n",
        "for column in numerical_columns:\n",
        "    bike_df = remove_outliers_iqr(bike_df, column)\n",
        "\n"
      ],
      "metadata": {
        "id": "IwHAoTcZhynh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visulizing after removing the outlier\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Select numerical columns\n",
        "numerical_columns = ['Rented_Bike_Count', 'Temperature', 'Humidity', 'Wind_speed', 'Visibility', 'Dew_point_temperature']\n",
        "\n",
        "for i, column in enumerate(numerical_columns, 1):\n",
        "    plt.subplot(2, 3, i)\n",
        "    sns.boxplot(y=bike_df[column])\n",
        "    plt.title(f'Box Plot of {column}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6elsfxjwh-lA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to remove outliers using IQR\n",
        "def remove_outliers_iqr(df, column):\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    # Filter out the outliers\n",
        "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
        "\n",
        "# List of numerical columns to treat\n",
        "numerical_columns = ['Rented_Bike_Count', 'Temperature', 'Humidity', 'Wind_speed', 'Visibility', 'Dew_point_temperature']\n",
        "\n",
        "# Apply the IQR method to treat outliers\n",
        "for column in numerical_columns:\n",
        "    bike_df = remove_outliers_iqr(bike_df, column)"
      ],
      "metadata": {
        "id": "SItn7gVrhkp-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "\n",
        "# Create a copy of the original DataFrame\n",
        "bike_df_encoded = bike_df.copy()\n",
        "\n",
        "# Encoding 'Functioning_Day' (Yes -> 1, No -> 0)\n",
        "bike_df_encoded['Functioning_Day'] = bike_df_encoded['Functioning_Day'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "# Encoding 'Holiday' (No Holiday -> 0, Holiday -> 1)\n",
        "bike_df_encoded['Holiday'] = bike_df_encoded['Holiday'].map({'No Holiday': 0, 'Holiday': 1})\n",
        "\n",
        "# Encoding 'weekday_or_weekend' (Weekday -> 0, Weekend -> 1)\n",
        "bike_df_encoded['weekday_or_weekend'] = bike_df_encoded['weekday_or_weekend'].map({'Weekday': 0, 'Weekend': 1})\n",
        "\n",
        "# One-hot encoding for 'Seasons', 'month', and 'day' columns\n",
        "bike_df_encoded = pd.get_dummies(bike_df_encoded, columns=['Seasons', 'month', 'day'], drop_first=True)\n",
        "\n",
        "# Convert boolean columns (from one-hot encoding) to integers\n",
        "bike_df_encoded = bike_df_encoded.astype(int)\n",
        "\n",
        "# Display the first few rows of the encoded DataFrame\n",
        "print(bike_df_encoded.head())\n"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "# Scaling your data\n",
        "\n",
        "# Selecting numeric features to scale\n",
        "numeric_features = ['Rented_Bike_Count', 'Hour', 'Temperature', 'Humidity',\n",
        "                    'Wind_speed', 'Visibility', 'Dew_point_temperature',\n",
        "                    'Solar_Radiation', 'Rainfall', 'Snowfall']\n",
        "\n",
        "# Applying Z-score Standardization\n",
        "scaler = StandardScaler()\n",
        "bike_df_encoded[numeric_features] = scaler.fit_transform(bike_df_encoded[numeric_features])\n",
        "\n",
        "# Checking the first few rows of the scaled DataFrame\n",
        "print(bike_df_encoded.head(10))"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "X = bike_df_encoded.drop('Rented_Bike_Count', axis=1)  # Features\n",
        "y = bike_df_encoded['Rented_Bike_Count']  # Target variable\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=24)\n",
        "\n",
        "# Output the shape of the splits to verify\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Fit the Algorithm\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the model\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print all important metrics\n",
        "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
        "print(f\"Mean Squared Error: {mse:.2f}\")\n",
        "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
        "print(f\"R-squared: {r2:.2f}\")\n"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Multiple Linear Regression algorithm predicts a continuous target variable by modeling the linear relationship between multiple independent features and the target. It assumes that the target variable is a linear combination of the input features."
      ],
      "metadata": {
        "id": "wkPoaKdWmx0u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Performance:                            \n",
        "Mean Absolute Error (MAE): 0.48 — shows an average error of 0.48 units in predictions.                        \n",
        "Mean Squared Error (MSE): 0.38 — captures squared prediction errors, with larger errors having a greater impact.                 \n",
        "Root Mean Squared Error (RMSE): 0.62 — provides a better sense of the prediction error magnitude.                        \n",
        "R-squared: 0.60 — indicates that 60% of the target's variability is explained by the model.                            \n",
        "The model performs moderately, but the errors suggest that further improvements, such as tuning, could be beneficial."
      ],
      "metadata": {
        "id": "wuMLumram3h1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "metrics = {\n",
        "    'Mean Absolute Error': mae,\n",
        "    'Mean Squared Error': mse,\n",
        "    'Root Mean Squared Error': rmse,\n",
        "    'R-squared': r2\n",
        "}\n",
        "\n",
        "# Creating the bar chart\n",
        "plt.figure(figsize=(7, 4))\n",
        "plt.bar(metrics.keys(), metrics.values(), color=['blue', 'orange', 'green', 'red'])\n",
        "plt.ylabel('Scores')\n",
        "plt.title('Evaluation Metrics')\n",
        "plt.ylim(0, max(metrics.values()) + 1)  # Set y-axis limit for better visualization\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Define a pipeline with StandardScaler and LinearRegression\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', LinearRegression())\n",
        "])\n",
        "\n",
        "# Define a set of hyperparameters to tune\n",
        "param_grid = {\n",
        "    'model__fit_intercept': [True, False],\n",
        "    'model__copy_X': [True, False]\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='r2', verbose=1)\n",
        "\n",
        "# Fit the Algorithm\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters and model\n",
        "best_model = grid_search.best_estimator_\n",
        "print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
        "\n",
        "# Predict on the model\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Evaluation metrics\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print all important metrics\n",
        "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
        "print(f\"Mean Squared Error: {mse:.2f}\")\n",
        "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
        "print(f\"R-squared: {r2:.2f}\")\n"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the code provided, I used GridSearchCV as the hyperparameter optimization technique. Here’s why this technique was chosen:\n",
        "\n",
        "Why GridSearchCV?\n",
        "\n",
        "1. Exhaustive Search:                          \n",
        "\n",
        "GridSearchCV performs an exhaustive search over all combinations of hyperparameters specified in the param_grid. This ensures that we explore every possible configuration of the hyperparameters within the given range.\n",
        "\n",
        "2. Small Hyperparameter Space:\n",
        "\n",
        "In this case, the number of hyperparameters to tune is relatively small (only two: fit_intercept and copy_X), and both are binary (True/False). This makes GridSearchCV a good choice because it can explore all combinations without becoming computationally expensive.\n",
        "\n",
        "3. Model Performance:\n",
        "\n",
        "Since GridSearchCV checks all combinations, it guarantees that the best-performing model will be selected from the specified hyperparameters.\n",
        "\n",
        "When to Use Other Techniques:\n",
        "\n",
        "RandomizedSearchCV:                  \n",
        "\n",
        "Useful when the hyperparameter space is large and an exhaustive search would take too long. It randomly samples a fixed number of configurations, which makes it faster.\n",
        "\n",
        "Bayesian Optimization (e.g., BayesSearchCV):           \n",
        "\n",
        "Efficient when there are many hyperparameters, or when you want to minimize the number of iterations while still exploring the search space intelligently. It builds a probabilistic model of the function mapping hyperparameters to model performance and tries to identify the best hyperparameters efficiently.\n",
        "Since our hyperparameter space is small, GridSearchCV was the best fit for this scenario, as it thoroughly checks every possible combination in a reasonable amount of time."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the RandomForestRegressor model\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=24)\n",
        "\n",
        "# Fit the model on training data\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print all important metrics\n",
        "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
        "print(f\"Mean Squared Error: {mse:.2f}\")\n",
        "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
        "print(f\"R-squared: {r2:.2f}\")\n"
      ],
      "metadata": {
        "id": "iNmsWrlOons1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "metrics = {\n",
        "    'Mean Absolute Error': mae,\n",
        "    'Mean Squared Error': mse,\n",
        "    'Root Mean Squared Error': rmse,\n",
        "    'R-squared': r2\n",
        "}\n",
        "\n",
        "# Creating the bar chart\n",
        "plt.figure(figsize=(7, 5))\n",
        "plt.bar(metrics.keys(), metrics.values(), color=['blue', 'orange', 'green', 'red'])\n",
        "plt.ylabel('Scores')\n",
        "plt.title('Evaluation Metrics')\n",
        "plt.ylim(0, max(metrics.values()) + 1)  # Set y-axis limit for better visualization\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Define the Random Forest Regressor\n",
        "rf_model = RandomForestRegressor(random_state=24)\n",
        "\n",
        "# Set up the parameter grid for tuning\n",
        "param_dist = {\n",
        "    'n_estimators': np.arange(50, 201, 10),  # Number of trees\n",
        "    'max_depth': [None] + list(np.arange(5, 21, 1)),  # Depth of each tree\n",
        "    'min_samples_split': [2, 5, 10],  # Minimum samples to split a node\n",
        "    'min_samples_leaf': [1, 2, 4],  # Minimum samples in a leaf node\n",
        "    'max_features': ['auto', 'sqrt', 'log2']  # Number of features to consider at each split\n",
        "}\n",
        "\n",
        "# Set up RandomizedSearchCV\n",
        "rf_random = RandomizedSearchCV(estimator=rf_model, param_distributions=param_dist, n_iter=100, cv=5, verbose=2,  random_state=24,  n_jobs=-1)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "rf_random.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model from the random search\n",
        "best_rf_model = rf_random.best_estimator_\n",
        "\n",
        "\n",
        "# Predict on the model\n",
        "y_pred = best_rf_model.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print the best parameters and metrics\n",
        "print(\"Best Parameters:\", rf_random.best_params_)\n",
        "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
        "print(f\"Mean Squared Error: {mse:.2f}\")\n",
        "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
        "print(f\"R-squared: {r2:.2f}\")\n"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation of Evaluation Metrics and Business Impact\n",
        "1. Mean Absolute Error (MAE)                  \n",
        "Indication: MAE measures the average magnitude of errors in a set of predictions, without considering their direction. It indicates how far the predictions are from the actual values on average.\n",
        "Business Impact: A lower MAE means the model's predictions are closer to the actual values, which is critical in business scenarios where accurate forecasting is vital (e.g., predicting bike rentals). High MAE can lead to inefficient resource allocation, inventory mismanagement, and reduced customer satisfaction.\n",
        "2. Mean Squared Error (MSE)                    \n",
        "Indication: MSE calculates the average of the squares of the errors, giving more weight to larger errors. It is sensitive to outliers, meaning that large prediction errors significantly impact the metric.\n",
        "Business Impact: A lower MSE indicates that the model is not only predicting accurately on average but is also minimizing large errors. In business, this is important for maintaining customer trust and ensuring that operations are planned based on accurate demand forecasts. High MSE can lead to financial losses due to unexpected demand spikes or drops.\n",
        "3. Root Mean Squared Error (RMSE)              \n",
        "Indication: RMSE provides the error magnitude in the same units as the target variable. It offers a clear understanding of the average error in predictions.\n",
        "Business Impact: RMSE is useful for assessing the model's prediction quality, helping businesses make informed decisions. For instance, a lower RMSE in bike rental predictions would mean that the company can better prepare for demand, leading to increased customer satisfaction and optimized fleet management. Conversely, a higher RMSE can lead to underutilization or overutilization of resources.\n",
        "4. R-squared (R²)                        \n",
        "Indication: R² indicates the proportion of variance in the target variable that is explained by the model. A higher R² value suggests that the model fits the data well.\n",
        "Business Impact: A high R² (e.g., 0.88) means that a significant portion of the target variable's variability is captured, providing confidence in the model's predictions. This is critical for strategic decision-making, such as marketing campaigns or operational strategies. A lower R² indicates that the model may not be sufficiently capturing the factors that influence the target variable, leading to potentially poor business decisions.\n",
        "Overall Business Impact of the ML Model\n",
        "The Random Forest Regressor model, with its evaluation metrics, provides valuable insights into the bike rental business. Accurate predictions of rented bikes can lead to:\n",
        "\n",
        "Improved Inventory Management: Better forecasts allow for optimized bike availability and maintenance scheduling.\n",
        "Enhanced Customer Satisfaction: Meeting customer demand effectively results in higher satisfaction and repeat business.\n",
        "Operational Efficiency: Accurate predictions can lead to cost savings in operations, marketing, and staffing, as resources can be allocated more effectively based on expected demand.\n",
        "Data-Driven Decisions: With reliable predictions, the business can make informed decisions regarding marketing strategies, promotions, and expansions.\n",
        "In summary, the evaluation metrics serve as critical indicators of the model's effectiveness, directly impacting business performance and decision-making processes."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "\n",
        "# Define the Gradient Boosting Regressor with default parameters\n",
        "gb_model = GradientBoostingRegressor(random_state=24)\n",
        "\n",
        "# Fit the Algorithm\n",
        "gb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the model\n",
        "y_pred = gb_model.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
        "print(f\"Mean Squared Error: {mse:.2f}\")\n",
        "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
        "print(f\"R-squared: {r2:.2f}\")\n"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Define the Gradient Boosting Regressor\n",
        "gb_model = GradientBoostingRegressor(random_state=24)\n",
        "\n",
        "# Set up the parameter grid for tuning\n",
        "param_dist = {\n",
        "    'n_estimators': np.arange(50, 201, 10),  # Number of boosting stages to be run\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],  # Step size shrinkage\n",
        "    'max_depth': np.arange(3, 11, 1),  # Depth of each tree\n",
        "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
        "    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
        "}\n",
        "\n",
        "# Set up RandomizedSearchCV\n",
        "gb_random = RandomizedSearchCV(estimator=gb_model,  param_distributions=param_dist,  n_iter=100, cv=5, verbose=2,  random_state=24,  n_jobs=-1)\n",
        "\n",
        "# Fit the model\n",
        "gb_random.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model from the random search\n",
        "best_gb_model = gb_random.best_estimator_\n",
        "\n",
        "# Predict on the test set using the best model\n",
        "y_pred = best_gb_model.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print the best parameters and metrics\n",
        "print(\"Best Parameters:\", gb_random.best_params_)\n",
        "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
        "print(f\"Mean Squared Error: {mse:.2f}\")\n",
        "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
        "print(f\"R-squared: {r2:.2f}\")"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Hyperparameter Optimization Technique Used: Randomized Search Cross-Validation (RandomizedSearchCV)**\n",
        "\n",
        "#### **Why Use Randomized Search?**\n",
        "1. **Efficiency**: RandomizedSearchCV evaluates a random subset of hyperparameter combinations, allowing for faster exploration of the hyperparameter space compared to Grid Search, which tests every possible combination.\n",
        "\n",
        "2. **Flexibility**: It enables the specification of a wide range of values for hyperparameters, making it easier to find optimal settings for complex models like Gradient Boosting.\n",
        "\n",
        "3. **Reduced Overfitting Risk**: By sampling a subset of hyperparameters, it helps mitigate the risk of overfitting to the validation set during the tuning process.\n",
        "\n",
        "4. **Balance Between Exploration and Exploitation**: It provides a balance between exploring new hyperparameter combinations and exploiting the best ones identified so far.\n",
        "\n",
        "### **Overall Benefits**:\n",
        "Using **RandomizedSearchCV** allows for effective hyperparameter tuning, leading to better model performance by optimizing key parameters such as the number of estimators, learning rate, maximum tree depth, and minimum samples for splitting and leaf nodes. This can result in more accurate predictions and a model better suited to the underlying data."
      ],
      "metadata": {
        "id": "ASVJVkRUp8zg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Bh2TTKg4p8zh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, there has been an improvement in the model's performance after applying hyperparameter tuning using **Randomized Search Cross-Validation**. Here’s a comparison of the evaluation metrics before and after tuning:\n",
        "\n",
        "### **Improvement Summary**\n",
        "\n",
        "#### **Before Hyperparameter Tuning:**\n",
        "- **Mean Absolute Error (MAE):** 0.26\n",
        "- **Mean Squared Error (MSE):** 0.15\n",
        "- **Root Mean Squared Error (RMSE):** 0.39\n",
        "- **R-squared (R²):** 0.84\n",
        "\n",
        "#### **After Hyperparameter Tuning:**\n",
        "- **Mean Absolute Error (MAE):** 0.14\n",
        "- **Mean Squared Error (MSE):** 0.07\n",
        "- **Root Mean Squared Error (RMSE):** 0.26\n",
        "- **R-squared (R²):** 0.93\n",
        "\n",
        "### **Evaluation Metric Score Chart:**\n",
        "\n",
        "| Metric                     | Before Tuning | After Tuning | Improvement            |\n",
        "|-----------------------------|---------------|--------------|-------------------------|\n",
        "| **Mean Absolute Error (MAE)**  | 0.26          | 0.14         | Decrease of 0.12        |\n",
        "| **Mean Squared Error (MSE)**   | 0.15          | 0.07         | Decrease of 0.08        |\n",
        "| **Root Mean Squared Error (RMSE)** | 0.39          | 0.26        | Decrease of 0.13        |\n",
        "| **R-squared (R²)**           | 0.84          | 0.93        | Increase of 0.09        |\n",
        "\n",
        "### **Conclusion**\n",
        "The hyperparameter tuning has resulted in:\n",
        "- A decrease in MAE, MSE, and RMSE, indicating fewer prediction errors.\n",
        "- An increase in R², suggesting that the model explains a greater portion of the variance in the target variable.\n",
        "\n",
        "Overall, these improvements indicate that the **Gradient Boosting Regressor** has become more accurate and reliable after hyperparameter optimization."
      ],
      "metadata": {
        "id": "aOuZDP7-p8zh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the Gradient Boosting Regressor, the following evaluation metrics were considered for their positive business impact:\n",
        "\n",
        "1. Mean Squared Error (MSE)                \n",
        "Importance: MSE measures the average squared difference between predicted and actual values, making it sensitive to larger errors.\n",
        "Business Impact:                \n",
        "A lower MSE indicates more accurate predictions, which is crucial for resource planning and operational efficiency. For instance, accurately predicting the number of rented bikes can help optimize fleet management, reducing costs associated with overstocking or shortages.\n",
        "By minimizing MSE, businesses can avoid potential losses caused by incorrect supply levels, ensuring that customer demand is met effectively.\n",
        "2. R-squared (R²)                        \n",
        "Importance: R² quantifies the proportion of variance in the target variable explained by the model, providing insights into the model's explanatory power.\n",
        "Business Impact:\n",
        "A high R² value suggests that the model captures the key factors influencing bike rentals, enabling better strategic decision-making. For example, understanding which features (like weather or time of day) significantly affect demand can lead to targeted marketing and operational adjustments.\n",
        "This metric helps build stakeholder confidence in the model's predictions, facilitating more informed budgeting and resource allocation strategies, ultimately contributing to improved business performance."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final Prediction Model Selection\n",
        "From the models implemented, I chose the Gradient Boosting Regressor as the final prediction model for the following reasons:\n",
        "\n",
        "1. Performance Metrics           \n",
        "The Gradient Boosting Regressor demonstrated strong performance in key evaluation metrics:\n",
        "\n",
        "Mean Absolute Error (MAE): 0.26\n",
        "Mean Squared Error (MSE): 0.15\n",
        "Root Mean Squared Error (RMSE): 0.39\n",
        "R-squared (R²): 0.84\n",
        "These metrics indicate that the model provides accurate predictions with minimal error, making it suitable for reliable demand forecasting in bike rentals.\n",
        "\n",
        "2. Handling Non-linearity             \n",
        "Gradient Boosting is an ensemble method that combines the predictions of multiple weak learners (decision trees) to create a strong predictive model. This allows it to capture complex relationships in the data that simpler models like Multiple Linear Regression might miss.\n",
        "3. Robustness to Overfitting           \n",
        "Through the hyperparameter tuning process, the model was optimized for performance, reducing the risk of overfitting while maintaining a high level of accuracy. This is crucial for ensuring the model generalizes well to unseen data.\n",
        "4. Feature Importance Insights              \n",
        "Gradient Boosting provides insights into feature importance, allowing the business to understand which factors most significantly impact bike rentals. This information can inform marketing strategies and operational decisions.\n",
        "5. Flexibility                \n",
        "The model is versatile and can be adapted to different datasets and business scenarios, making it a valuable tool for ongoing analysis and prediction.\n",
        "Conclusion\n",
        "Given its strong predictive performance, ability to handle complex relationships, and insights into feature importance, the Gradient Boosting Regressor was selected as the final prediction model. This choice aligns well with the business's need for accurate, reliable forecasts to optimize bike rental operations and enhance customer satisfaction."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this machine learning project, we aimed to predict the number of rented bikes using various regression algorithms, culminating in the selection of the best-performing model based on evaluation metrics and model explainability.\n",
        "\n",
        "1. Model Selection: We explored multiple algorithms, including Multiple Linear Regression, Random Forest Regressor, and Gradient Boosting Regressor. Each model was evaluated based on key performance metrics: Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and R-squared (R²). After thorough evaluation, the Gradient Boosting Regressor emerged as the best-performing model, achieving a Mean Absolute Error of 0.14, a Mean Squared Error of 0.07, a Root Mean Squared Error of 0.26, and an R-squared of 0.93. These results indicate that the model has good predictive power and captures a significant portion of the variability in the dataset.\n",
        "\n",
        "2. Hyperparameter Tuning: We employed RandomizedSearchCV for hyperparameter tuning, which enabled us to optimize the model's performance by selecting the best parameters. This step was crucial in enhancing the model's accuracy, demonstrating the importance of hyperparameter optimization in machine learning.\n",
        "\n",
        "3. Model Explainability: To gain insights into the model's decision-making process, we utilized SHAP (SHapley Additive exPlanations) values. This approach allowed us to understand the contribution of each feature to the predictions, highlighting the most influential variables affecting bike rentals. The insights obtained through SHAP provided valuable business intelligence, which can help in making data-driven decisions.\n",
        "\n",
        "4. Business Impact: The ability to accurately predict bike rentals has significant implications for bike-sharing services and urban mobility initiatives. By understanding rental patterns, operators can optimize fleet management, enhance customer satisfaction, and improve operational efficiency. The predictive model serves as a powerful tool for strategic planning and resource allocation.\n",
        "\n",
        "5. Future Work: While the Gradient Boosting Regressor performed well, there are opportunities for further improvement. Future work could explore additional algorithms, ensemble methods, or even deep learning approaches. Moreover, incorporating external factors such as weather data or events could enhance prediction accuracy.\n",
        "\n",
        "In summary, this project successfully demonstrated the application of machine learning in predicting bike rentals, showcasing the importance of model selection, tuning, and explainability in developing effective predictive models. The insights gained can drive business strategies and contribute to the overall efficiency of bike-sharing programs."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}